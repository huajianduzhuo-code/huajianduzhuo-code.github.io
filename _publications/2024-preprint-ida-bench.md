---
title: "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis"
collection: publications
category: preprints
permalink: /publication/2024-preprint-ida-bench
excerpt: 'A benchmark for evaluating Large Language Models on interactive data analysis tasks.'
date: 2024-11-01
venue: 'arXiv Preprint'
paperurl: 'https://arxiv.org/abs/2505.18223'
citation: 'H. Li, H. Liu, T. Zhu, T. Guo, Z. Zheng, X. Deng, M. Jordan. (2024). "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis." <i>arXiv preprint</i>.'
---

IDA-Bench is a comprehensive benchmark designed to evaluate Large Language Models on interactive guided data analysis tasks. The benchmark tests LLMs' abilities to understand data, generate appropriate analyses, and respond to user guidance.

**Authors**: H. Li†, H. Liu†, T. Zhu†, T. Guo†, Z. Zheng, X. Deng, M. Jordan (†co-first author)

